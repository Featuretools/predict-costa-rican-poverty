{
  "cells": [
    {
      "metadata": {
        "_uuid": "1a87dfa6b419deab71f1a128e3bf80a6a0b519ac"
      },
      "cell_type": "markdown",
      "source": "# Featuretools for Good\n\nIn this notebook, we will implement automated feature engineering with [Featuretools](https://docs.featuretools.com/#minute-quick-start) for the Costa Rican Household Poverty Challenge. This code implements only a basic version of Featuretools but the library has much more to offer! \n\n## Automated Feature Engineering\n\nAutomated feature engineering should be a _default_ part of your data science workflow. Manual feature engineering is limited both by human creativity and time constraints but automated methods have no such constraints. At the moment, Featuretools is the only open-source Python library available for automated feature engineering. This library is extremely easy to get started with and very powerful (as the score from this kernel illustrates). \n\nFor anyone new to featuretools, check out the [documentation](https://docs.featuretools.com/getting_started/install.html) or an [introductory blog post here.](https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219) "
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np \nimport pandas as pd\n\nimport featuretools as ft",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e511a5ea8fff2f8ce3ac3a457eca2feeaacbb037"
      },
      "cell_type": "markdown",
      "source": "We'll read in the data and join the training and testing set together. "
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Raw data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntest['Target'] = np.nan\n\ndata = train.append(test, sort = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6fbf5be29712683b8c385b867f2247e422ba7ece"
      },
      "cell_type": "markdown",
      "source": "### Data Preprocessing \n\nThese steps are laid out in the kernel [Start Here: A Complete Walkthrough](https://www.kaggle.com/willkoehrsen/start-here-a-complete-walkthrough). Mostly we correct the labels, extract the labels for the heads of households, and establish a base dataframe for making submisions."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80e06e60683d8e513992cce5fea4b089dbc3f1ea",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Groupby the household and figure out the number of unique values\nall_equal = train.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n\n# Households where targets are not all equal\nnot_equal = all_equal[all_equal != True]\nprint('There are {} households where the family members do not all have the same target.'.format(len(not_equal)))\n\n# Iterate through each household\nfor household in not_equal.index:\n    # Find the correct label (for the head of household)\n    true_target = int(train[(train['idhogar'] == household) & (train['parentesco1'] == 1.0)]['Target'])\n    \n    # Set the correct label for all members in the household\n    train.loc[train['idhogar'] == household, 'Target'] = true_target\n    \n# Groupby the household and figure out the number of unique values\nall_equal = train.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n\n# Households where targets are not all equal\nnot_equal = all_equal[all_equal != True]\nprint('There are {} households where the family members do not all have the same target.'.format(len(not_equal)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8a3f5652300b83789c2fc01f9944be947233e3c9"
      },
      "cell_type": "markdown",
      "source": "Here we extract the train labels for the heads of households."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "47f8ccb73d83c9d026690da139967a53e876f2bf",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_valid_labels = train.loc[train['parentesco1'] == 1, ['idhogar', 'Target']].copy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fc8d9ea3fb4f554fb784a3e1019acd5e4bb5decc"
      },
      "cell_type": "markdown",
      "source": "We need to make predictions for _all individuals_ in the test data, but only the predictions for the heads of household are scored."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "fd76091716fe5e2167369cceeba7aa08c15375b8"
      },
      "cell_type": "code",
      "source": "submission_base = test.loc[:, ['idhogar', 'Id']]\nsubmission_base['idhogar'] = submission_base['idhogar']\n\n# The tests ids are only for the heads of households.\ntest_ids = list(test.loc[test['parentesco1'] == 1, 'idhogar'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a10b0ed8a9d6cb8acb43590c6ddc3e2904cf21bf"
      },
      "cell_type": "markdown",
      "source": "### Convert object types to floats\n\nThe mapping is explained in the data description. These are continuous variables and should be converted to numeric floats."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "808056c39087e5ef59c0131ee73e2a47b610f71e"
      },
      "cell_type": "code",
      "source": "mapping = {\"yes\": 1, \"no\": 0}\n\n# Fill in the values with the correct mapping\ndata['dependency'] = data['dependency'].replace(mapping).astype(np.float64)\ndata['edjefa'] = data['edjefa'].replace(mapping).astype(np.float64)\ndata['edjefe'] = data['edjefe'].replace(mapping).astype(np.float64)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1dd27d18673153236e05c001dc60bec879a92d2e"
      },
      "cell_type": "markdown",
      "source": "### Handle Missing Values\n\nThe logic for these choices is explained in the [Start Here: A Complete Walkthrough](https://www.kaggle.com/willkoehrsen/start-here-a-complete-walkthrough) kernel. This might not be optimal, but it has improved cross-validation results."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "2b64197ee2656a1d69c94e0c6ffd1c76dd91619b"
      },
      "cell_type": "code",
      "source": "data['v18q1'] = data['v18q1'].fillna(0)\ndata.loc[(data['tipovivi1'] == 1), 'v2a1'] = 0\ndata['rez_esc'] = data['rez_esc'].fillna(0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "17b36b4846334fcb78ecdd089564701d4b5b6efc"
      },
      "cell_type": "markdown",
      "source": "### Remove Squared Variables\n\nThe gradient boosting machine does not need the squared version of variables it if already has the original variables. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c564ef909f8d1bf861a3cb8b573106a7297894a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "data = data[[x for x in data if not x.startswith('SQB')]]\ndata = data.drop(columns = ['agesq'])\ndata.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e29e93c437bd63a0e9f8b5596aa6040d1859984f"
      },
      "cell_type": "code",
      "source": "import featuretools.variable_types as vtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7bfb23571103d16934da45554ba02d4f915e9519"
      },
      "cell_type": "markdown",
      "source": "#  Establish Correct Variable Types\n\nWe need to specify the correct variables types:\n\n1. Individual Variables: these are characteristics of each individual rather than the household\n    * Boolean: Yes or No (0 or 1)\n    * Ordered Discrete: Integers with an ordering\n2. Household variables\n    * Boolean: Yes or No\n    * Ordered Discrete: Integers with an ordering\n    * Continuous numeric\n\nBelow we manually define the variables in each category. This is a little tedious, but also necessary."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "975463b8c6841e6894d6be8a733e29fb1386fcde",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "hh_bool = ['hacdor', 'hacapo', 'v14a', 'refrig', 'paredblolad', 'paredzocalo', \n           'paredpreb','pisocemento', 'pareddes', 'paredmad',\n           'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisoother', \n           'pisonatur', 'pisonotiene', 'pisomadera',\n           'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', \n           'abastaguadentro', 'abastaguafuera', 'abastaguano',\n            'public', 'planpri', 'noelec', 'coopele', 'sanitario1', \n           'sanitario2', 'sanitario3', 'sanitario5',   'sanitario6',\n           'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', \n           'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', \n           'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3',\n           'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', \n           'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', \n           'computer', 'television', 'lugar1', 'lugar2', 'lugar3',\n           'lugar4', 'lugar5', 'lugar6', 'area1', 'area2']\n\nhh_ordered = [ 'rooms', 'r4h1', 'r4h2', 'r4h3', 'r4m1','r4m2','r4m3', 'r4t1',  'r4t2', \n              'r4t3', 'v18q1', 'tamhog','tamviv','hhsize','hogar_nin',\n              'hogar_adul','hogar_mayor','hogar_total',  'bedrooms', 'qmobilephone']\n\nhh_cont = ['v2a1', 'dependency', 'edjefe', 'edjefa', 'meaneduc', 'overcrowding']\n\nhousehold_types = {variable: vtypes.Boolean for variable in hh_bool}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "4eff666cd77701b3787bc74c42f146b67219c070"
      },
      "cell_type": "code",
      "source": "ind_bool = ['v18q', 'dis', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', \n            'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n            'parentesco1', 'parentesco2',  'parentesco3', 'parentesco4', 'parentesco5', \n            'parentesco6', 'parentesco7', 'parentesco8',  'parentesco9', 'parentesco10', \n            'parentesco11', 'parentesco12', 'instlevel1', 'instlevel2', 'instlevel3', \n            'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', \n            'instlevel9', 'mobilephone']\n\nind_types = {variable: vtypes.Boolean for variable in ind_bool}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0579f590db9153c4a68720e81b7a341cede4d009"
      },
      "cell_type": "markdown",
      "source": "Below we convert the `Boolean` variables to the correct type. "
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "801e6565b54d6797c694b9a4666250203036fd2e"
      },
      "cell_type": "code",
      "source": "for variable in (hh_bool + ind_bool):\n    data[variable] = data[variable].astype('bool')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c94d438dddaa1c2e08259a3a2ed01118173d328f"
      },
      "cell_type": "markdown",
      "source": "# Create an EntitySet"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "63901e5cabcba3760dd711f9086d4023dca4eb7e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "es = ft.EntitySet(id = 'houses')\nes.entity_from_dataframe(entity_id = 'ind', dataframe = data, \n                         index = 'Id', variable_types=ind_types)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "78b1b739b016732e5ad504f92f632eea3ebd92ed"
      },
      "cell_type": "markdown",
      "source": "# Normalize Household Table\n\nThis creates a second table with one row for each household. We want to make features on a household level, and this allows us to do so in a few lines of code."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ab897f0260e7dda326a0d0ecdbf1c613c1bf6088",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "es.normalize_entity(base_entity_id='ind', new_entity_id='household', \n                    index = 'idhogar', variable_types=household_types, \n                    additional_variables = hh_bool + hh_ordered + hh_cont)\nes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bb81ef01856ffe3d01bcf2ba6005dffda1c1836a"
      },
      "cell_type": "markdown",
      "source": "Normalizing the entity automatically ads in the relationship between the parent, `household`, and the child, `ind`. When Featuretools makes features, it will aggregate the children for each parent. "
    },
    {
      "metadata": {
        "_uuid": "0808dac4226963c7d2c78d8a39bf3eae949d56f1"
      },
      "cell_type": "markdown",
      "source": "# Deep Feature Synthesis\n\nHere is where Featuretools gets to work. This single function call will aggregate all of the variables it can in the individual level data, applying the appropriate primitives for each data type."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "755c363b6648af063d4d5a2b4c944952dc91c64d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "feature_matrix, feature_names = ft.dfs(entityset=es, target_entity = 'household', \n                                       max_depth = 2, verbose = 1, \n                                       n_jobs = -1, chunk_size = 100)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9154c4be3ba4b60868e1ae4eeef3bcd205fecdd9"
      },
      "cell_type": "markdown",
      "source": "We need to remove any columns containing derivations of the `Target`."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ad41824d9092f1ee2c494632dbab4a1d084f92a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "drop_cols = []\nfor col in feature_matrix:\n    if col == 'Target':\n        pass\n    else:\n        if 'Target' in col:\n            drop_cols.append(col)\n            \nfeature_matrix = feature_matrix[[x for x in feature_matrix if x not in drop_cols]]         \nfeature_matrix.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "eecd9bdeaa87e0101c9012e54e2accbc52455bae"
      },
      "cell_type": "markdown",
      "source": "Most of these features are aggregations we could have made ourselves. However, why go to the trouble if Featuretools can do that for us?"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80a52160943fcac264829ff40240df79659e04c7",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "feature_matrix.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "eb905e8a23c09094e7934b93b85fb20a9166d323"
      },
      "cell_type": "markdown",
      "source": "That one call alone gave us 147 features to train a model."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "547f7ad357c850af4fe1b0446265aa7d918ad52c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "feature_matrix = feature_matrix.merge(train_valid_labels, on = 'idhogar', how = 'left')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "760ff2c661f5df3db42006ea4352535edefff631"
      },
      "cell_type": "markdown",
      "source": "# Feature Selection\n\nWe can do some rudimentary feature selection, removing one of any pair of columns with a correlation greater than 0.99 (absolute value)."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "438501339f06e3a81979d52e1668850ff1eb1638",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Create correlation matrix\ncorr_matrix = feature_matrix.corr().abs()\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(upper[column] >= 0.99)]\n\nprint('There are {} columns with >= 0.99 correlation.'.format(len(to_drop)))\nto_drop",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9b72d2c56f7e7f91e974c459af8865607c994ef4"
      },
      "cell_type": "code",
      "source": "feature_matrix = feature_matrix[[x for x in feature_matrix if x not in to_drop]]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "06e98a366140a0c1f288c2c999f924569581aa8a"
      },
      "cell_type": "markdown",
      "source": "### Training and Testing Data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eca5f1b3f93b43d225345801819b9cd186f37b65",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train = feature_matrix[feature_matrix['Target'].notnull()]\ntest = feature_matrix[feature_matrix['Target'].isnull()]\ntrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ce1ea677e496b4befde5a3773281f43ef76541f1"
      },
      "cell_type": "markdown",
      "source": "# Correlations with the target"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b13d3c3c1657f0a3a2728d79b7cd3a6be01ab841",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "corrs = train.corr()\ncorrs['Target'].sort_values(ascending = True).head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cb2e9a8988bc664a4c4db31027f084f3e2259052",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "corrs['Target'].sort_values(ascending = True).dropna().tail(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c7baeef6f120653785471ab6025a112932d7a9aa"
      },
      "cell_type": "markdown",
      "source": "Featuretools has built features with moderate correlations with the `Target`. Although these correlations only show linear relationships, they can still provide an approximation of what features will be \"useful\" to a machine learning model."
    },
    {
      "metadata": {
        "_uuid": "64e3ee30515f7f6b059428988b00cb4f724b5649"
      },
      "cell_type": "markdown",
      "source": "### Labels for Training"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "222c730f5611f6beed08fd78f12b8a9e0200701f"
      },
      "cell_type": "code",
      "source": "train_labels = np.array(train.pop('Target')).reshape((-1,))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0cf45f8a476a9b781d7183d51c8d28bbbbd04951"
      },
      "cell_type": "markdown",
      "source": "We'll now get into modeling. The gradient boosting machine implemented in LightGBM usually does well! "
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d80f9c0acfeb4fa6f39ff2f70673e8bb28619fbb"
      },
      "cell_type": "code",
      "source": "# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom collections import Counter\nfrom sklearn.metrics import f1_score, make_scorer\nfrom sklearn.model_selection import StratifiedKFold\n\nimport lightgbm as lgb",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "31775b68ae2427bd2ffa6af7daa171cdc29ae7dc"
      },
      "cell_type": "markdown",
      "source": "## Custom Evaluation Metric for LightGBM\n\nThis is the F1 Macro score used by the competition. Defining a custom evaluation metric for Light GBM is not exactly straightforward but we can manage."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "592f86efe45657e56af6e8300be86b2e9430a251"
      },
      "cell_type": "code",
      "source": "def macro_f1_score(labels, predictions):\n    # Reshape the predictions as needed\n    predictions = predictions.reshape(len(np.unique(labels)), -1 ).argmax(axis = 0)\n    \n    metric_value = f1_score(labels, predictions, average = 'macro')\n    \n    # Return is name, value, is_higher_better\n    return 'macro_f1', metric_value, True",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9e2fad73e520a69b170e50965f73be4fea660847"
      },
      "cell_type": "markdown",
      "source": "# Modeling with Gradient Boosting Machine\n\nThe hyperparameters used here _have not been optimized_. This is meant only as a first pass at modeling with these features. "
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "70aa9877b14ad7eeb19af201fb7748c656efd9ac"
      },
      "cell_type": "code",
      "source": "def model_gbm(features, labels, test_features, test_ids, nfolds = 5, return_preds = False):\n    \"\"\"Model using the GBM and cross validation.\n       Trains with early stopping on each fold.\n       Hyperparameters probably need to be tuned.\"\"\"\n    \n    feature_names = list(features.columns)\n    \n    # Model with hyperparameters selected from previous work\n    model = lgb.LGBMClassifier(boosting_type = 'gbdt', n_estimators = 10000, max_depth = -1,\n                               learning_rate = 0.025, metric = 'None', min_child_samples = 30,\n                               reg_alpha = 0.35, reg_lambda = 0.6, num_leaves = 15, \n                               colsample_bytree = 0.85, objective = 'multiclass', \n                               class_weight = 'balanced', \n                               n_jobs = -1)\n    \n    # Using stratified kfold cross validation\n    strkfold = StratifiedKFold(n_splits = nfolds, shuffle = True)\n    predictions = pd.DataFrame()\n    importances = np.zeros(len(feature_names))\n    \n    # Convert to arrays for indexing\n    features = np.array(features)\n    test_features = np.array(test_features)\n    labels = np.array(labels).reshape((-1 ))\n    \n    valid_scores = []\n    \n    # Iterate through the folds\n    for i, (train_indices, valid_indices) in enumerate(strkfold.split(features, labels)):\n        # Dataframe for \n        fold_predictions = pd.DataFrame()\n        \n        # Training and validation data\n        X_train = features[train_indices]\n        X_valid = features[valid_indices]\n        y_train = labels[train_indices]\n        y_valid = labels[valid_indices]\n        \n        # Train with early stopping\n        model.fit(X_train, y_train, early_stopping_rounds = 100, \n                  eval_metric = macro_f1_score,\n                  eval_set = [(X_train, y_train), (X_valid, y_valid)],\n                  eval_names = ['train', 'valid'],\n                  verbose = 200)\n        \n        # Record the validation fold score\n        valid_scores.append(model.best_score_['valid']['macro_f1'])\n        \n        # Make predictions from the fold\n        fold_probabilitites = model.predict_proba(test_features)\n        \n        # Record each prediction for each class as a column\n        for j in range(4):\n            fold_predictions[(j + 1)] = fold_probabilitites[:, j]\n            \n        fold_predictions['idhogar'] = test_ids\n        fold_predictions['fold'] = (i+1)\n        predictions = predictions.append(fold_predictions)\n        \n        importances += model.feature_importances_ / nfolds    \n\n    feature_importances = pd.DataFrame({'feature': feature_names,\n                                        'importance': importances})\n    valid_scores = np.array(valid_scores)\n    print(f'{nfolds} cross validation score: {round(valid_scores.mean(), 5)} with std: {round(valid_scores.std(), 5)}.')\n    \n    # If we want to examine predictions don't average over folds\n    if return_preds:\n        predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n        predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n        return predictions, feature_importances\n    \n    # Average the predictions over folds\n    predictions = predictions.groupby('idhogar', as_index = False).mean()\n    \n    # Find the class and associated probability\n    predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n    predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n    predictions = predictions.drop(columns = ['fold'])\n    \n    # Merge with the base to have one prediction for each individual\n    submission = submission_base.merge(predictions[['idhogar', 'Target']], on = 'idhogar', how = 'left').drop(columns = ['idhogar'])\n        \n    submission['Target'] = submission['Target'].fillna(4).astype(np.int8)\n    \n    # return the submission and feature importances\n    return submission, feature_importances, valid_scores",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3da68089f49ce1f4686210bfb4ef159c3413585e"
      },
      "cell_type": "markdown",
      "source": "Remove any households that do not have a head of household in the testing data. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a6eef36dfcc914a36229c16ecd4c22c3964a20a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test = test[test['PERCENT_TRUE(ind.parentesco1)'] != 0]\ntest_ids = list(test['idhogar'])\ntest.drop(columns = ['Target', 'idhogar'], inplace = True)\ntest.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "599064b9577ccbf32eae8c125cb40c02ab11cc0d"
      },
      "cell_type": "markdown",
      "source": "The train and test datasets must have the same columns. We can ensure this with the `align` operation."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f28a125d78aadf1ca91e6d2a3f586c64a495f6fc",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_ids = list(train['idhogar'])\ntrain, test = train.align(test, join = 'inner', axis = 1)\ntrain.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cb8e94be3c526e0492df7e8682c287138d531f4e"
      },
      "cell_type": "markdown",
      "source": "We need to make sure the length of the labels matches the length of the training dataset."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "51430d3c44b62a799b71c794ae80647219161010",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "len(train_labels) == train.shape[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a6eeb2ed1b507c67a0d2a5c5932f5b28b33313d1"
      },
      "cell_type": "markdown",
      "source": "We should also make sure the len of `test_ids` (the `idhogar` of the testing households) is the same as the length of the testing dataset."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "447a9150e2a176240a7cabd5b08e9b88e9b7200c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "len(test_ids) == test.shape[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b378afa97001178195ff8b778caa43df61fa19db"
      },
      "cell_type": "markdown",
      "source": "All that's left is to model! Our first call will return the predictions themselves which are in probabilities rather than the submission dataframe. We can look at the probabilities broken down by fold to see when our model is most confident."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8819b8b87fab831613ea966405e468d35fb2887e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "predictions, feature_importances = model_gbm(train, train_labels, test, test_ids, 5, True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a4074ec370603f46bcd8810d6429de81fbaee4d6",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.rcParams['font.size'] = 18\ng = sns.FacetGrid(predictions, row = 'fold', hue = 'Target', size = 3, aspect = 4)\ng.map(sns.kdeplot, 'confidence');\ng.add_legend();\nplt.suptitle('Distribution of Confidence by Fold and Color', y = 1.05);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4416bc9c85ee9f723d75b57436cf98fc94fdfb3d"
      },
      "cell_type": "markdown",
      "source": "Our model is not very confident on any fold for any of the predictions. Overall, the class 4 seems to have the highest confidence, which makes sense because there are the most examples of this class in the data."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c14204104a5dc31d8a6ae50542aec037a9c90bde",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "predictions.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "45fd7cc724ee4df0013e93f09cdf8f3d423adf62",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize = (24, 12))\nsns.violinplot(x = 'Target', y = 'confidence', hue = 'fold', data = predictions);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1910231b93a52823c915dc4c393100e3fe0a5ee2"
      },
      "cell_type": "markdown",
      "source": "Again, we see that class 4 has the highest confidence. There is significant difference in confidence levels across folds indications the predictions are not stable and depend heavily on the training data. Therefore, these predictions have high bias. We can potentially fix this by increasing the number of cross validation folds or by changing the sampling of the data (risky)."
    },
    {
      "metadata": {
        "_uuid": "1f2a4606e25c06bde55298f5d8148a15bfd084c9"
      },
      "cell_type": "markdown",
      "source": "The next line models and returns the actual submissions for uploading. We'll also create a dataframe to keep track of the modeling results."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "09b89dd670c8f2799aee6b6b7dbc16d0ca54981b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "submission, feature_importances, valid_scores = model_gbm(train, train_labels, test, test_ids, 5)\n\nresults = pd.DataFrame({'version': ['default_5fold'], 'F1-mean': [valid_scores.mean()], 'F1-std': [valid_scores.std()]})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1e1499385e42527d829ffbd5109cff16a5581b55"
      },
      "cell_type": "markdown",
      "source": "I'm not running the GBM with a random seed so the same set of features can produce different cross validation results. A random seed would ensure consistent results, but may have a singificant effect on the predictions. I don't want to get caught up trying to find the \"right\" random seed so I'm letting the predictions wander for now!"
    },
    {
      "metadata": {
        "_uuid": "bbb70e6e9b08327e3cc0e64c6f999dc665923054"
      },
      "cell_type": "markdown",
      "source": "## Feature Importances\n\nThe utility function below plots feature importances and can show us how many features are needed for a certain cumulative level of importance. "
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "2d13fe0581e8516daf1c620c1937ec6f4bb16a79"
      },
      "cell_type": "code",
      "source": "def plot_feature_importances(df, n = 15, return_features = False, threshold = None):\n    \"\"\"Plots n most important features. Also plots the cumulative importance if\n    threshold is specified and prints the number of features needed to reach threshold cumulative importance.\n    Intended for use with any tree-based feature importances. \n    \n    Args:\n        df (dataframe): Dataframe of feature importances. Columns must be \"feature\" and \"importance\".\n    \n        n (int): Number of most important features to plot. Default is 15.\n    \n        threshold (float): Threshold for cumulative importance plot. If not provided, no plot is made. Default is None.\n        \n    Returns:\n        df (dataframe): Dataframe ordered by feature importances with a normalized column (sums to 1) \n                        and a cumulative importance column\n    \n    Note:\n    \n        * Normalization in this case means sums to 1. \n        * Cumulative importance is calculated by summing features from most to least important\n        * A threshold of 0.9 will show the most important features needed to reach 90% of cumulative importance\n    \n    \"\"\"\n    \n    # Sort features with most important at the head\n    df = df.sort_values('importance', ascending = False).reset_index(drop = True)\n    \n    # Normalize the feature importances to add up to one and calculate cumulative importance\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    df['cumulative_importance'] = np.cumsum(df['importance_normalized'])\n    \n    plt.rcParams['font.size'] = 12\n    \n    # Bar plot of n most important features\n    df.loc[:n, :].plot.barh(y = 'importance_normalized', \n                            x = 'feature', color = 'blue', \n                            edgecolor = 'k', figsize = (12, 8),\n                            legend = False)\n\n    plt.xlabel('Normalized Importance', size = 18); plt.ylabel(''); \n    plt.title(f'Top {n} Most Important Features', size = 18)\n    plt.gca().invert_yaxis()\n    \n    \n    if threshold:\n        # Cumulative importance plot\n        plt.figure(figsize = (8, 6))\n        plt.plot(list(range(len(df))), df['cumulative_importance'], 'b-')\n        plt.xlabel('Number of Features', size = 16); plt.ylabel('Cumulative Importance', size = 16); \n        plt.title('Cumulative Feature Importance', size = 18);\n        \n        # Number of features needed for threshold cumulative importance\n        # This is the index (will need to add 1 for the actual number)\n        importance_index = np.min(np.where(df['cumulative_importance'] > threshold))\n        \n        # Add vertical line to plot\n        plt.vlines(importance_index + 1, ymin = 0, ymax = 1.05, linestyles = '--', colors = 'red')\n        plt.show();\n        \n        print('{} features required for {:.0f}% of cumulative importance.'.format(importance_index + 1, \n                                                                                  100 * threshold))\n    if return_features:\n        return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3a2edd2c24726e07751e1594b56632546a4374eb",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plot_feature_importances(feature_importances)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "aa2fe688f07bc08a783c1f5ea78bc54122bcc634"
      },
      "cell_type": "code",
      "source": "submission.to_csv('ft_baseline.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46c82f7824baf9788a141b7d546b60fccedb4644",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "submission['Target'].value_counts().sort_index().plot.bar(color = 'blue');\nplt.title('Distribution of Predicted Labels for Individuals', size = 14);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1786d5bb57505756e6918499f19a78c5308e784d"
      },
      "cell_type": "markdown",
      "source": "These shows the predictions on an individual, not household level (we set all individuals to 4 if they did not have a head of household). The distribution is close to what we observe in the training labels, which are provided on the household level."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e307346e91592edea149fa24051a0b1eaa997d6a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "data[data['Target'].notnull()]['Target'].value_counts().sort_index().plot.bar(color = 'blue');\nplt.title('Distribution of Labels for Training Individuals', size = 12);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ca7f10e654bb5df6438feded1c3d84139ccb2122"
      },
      "cell_type": "markdown",
      "source": "# Custom Primitive\n\nTo expand the capabilities of featuretools, we can write our own primitives to be applied to the data. We'll write a simple function that finds the range of a numeric column. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0998521e75128f8ddbf82fd9f44191cb922191c3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from featuretools.primitives import make_agg_primitive\n\n# Custom primitive\ndef range_calc(numeric):\n    return np.max(numeric) - np.min(numeric)\n\nrange_ = make_agg_primitive(function = range_calc,\n                            input_types = [ft.variable_types.Numeric], \n                            return_type = ft.variable_types.Numeric)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "17231d1e060905541bfa9b148f0957470c88df91"
      },
      "cell_type": "markdown",
      "source": "We can also make a custom primitive that calculates the correlation coefficient between two columns."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e1b54d927a24ba1278b80cd974b07a05850c272a"
      },
      "cell_type": "code",
      "source": "def p_corr_calc(numeric1, numeric2):\n    return np.corrcoef(numeric1, numeric2)[0, 1]\n\npcorr_ = make_agg_primitive(function = p_corr_calc,\n                            input_types = [ft.variable_types.Numeric, ft.variable_types.Numeric], \n                            return_type = ft.variable_types.Numeric)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f5a37e1fc09bb748548242fdaca5d0c918ef1a57"
      },
      "cell_type": "markdown",
      "source": "## More Featuretools\n\nWhy stop with 150 features? Let's add in a few more primitives and start creating more. To prevent featuretools from building the exact same features we already have, we can add `drop_exact` and pass in the feature names. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9dc2f2fc0897ad15064b8566f34a11d39b4cbbf",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "feature_matrix_add, feature_names_add = ft.dfs(entityset=es, target_entity = 'household', \n                                              agg_primitives = ['min', 'max', 'mean', 'percent_true', 'all', 'any',\n                                                             'sum', 'skew', 'std', range_],\n                                          trans_primitives = [], drop_exact = list(train.columns),\n                                          max_depth = 2, \n                                          verbose = 1, n_jobs = -1, \n                                          chunk_size = 100)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "b8f0c5cb3a31a69bf8f53a9dddf1ef348d0520b2"
      },
      "cell_type": "code",
      "source": "feature_matrix = pd.concat([feature_matrix, feature_matrix_add], axis = 1)\nfeatures = feature_names_add + feature_names",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1252b51e71965fd94da230ebfadc28e1b3763fd7",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "feature_matrix.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a860660b6192de3d66c794e5d9afb9bd095e6eee"
      },
      "cell_type": "markdown",
      "source": "# Post Processing Function\n\nThere are a number of steps after generating the feature matrix so let's put all of these in a function. We'll also start removing columns with more than a certain percentage of missing values."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "04b2c2184d476050ea7cb5ded693f8f38d49f388",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def post_process(feature_matrix, missing_threshold = 0.95, correlation_threshold = 0.99):\n    \n    feature_matrix = feature_matrix.replace({np.inf: np.nan, -np.inf:np.nan})\n    \n    ids = feature_matrix.pop('idhogar')\n    labels = feature_matrix.pop('Target')\n    \n    # One hot encoding (if necessary)\n    feature_matrix = pd.get_dummies(feature_matrix)\n    n_features_start = feature_matrix.shape[1]\n    print('Original shape: ', feature_matrix.shape)\n    \n    # Find missing and percentage\n    missing = pd.DataFrame(feature_matrix.isnull().sum())\n    missing['fraction'] = missing[0] / feature_matrix.shape[0]\n    missing.sort_values('fraction', ascending = False, inplace = True)\n\n    # Missing above threshold\n    missing_cols = list(missing[missing['fraction'] > missing_threshold].index)\n    n_missing_cols = len(missing_cols)\n\n    # Remove missing columns\n    feature_matrix = feature_matrix[[x for x in feature_matrix if x not in missing_cols]]\n    print('{} missing columns with threshold: {}.'.format(n_missing_cols, missing_threshold))\n    \n    # Zero variance\n    unique_counts = pd.DataFrame(feature_matrix.nunique()).sort_values(0, ascending = True)\n    zero_variance_cols = list(unique_counts[unique_counts[0] == 1].index)\n    n_zero_variance_cols = len(zero_variance_cols)\n\n    # Remove zero variance columns\n    feature_matrix = feature_matrix[[x for x in feature_matrix if x not in zero_variance_cols]]\n    print('{} zero variance columns.'.format(n_zero_variance_cols))\n    \n    # Correlations\n    corr_matrix = feature_matrix.corr()\n\n    # Extract the upper triangle of the correlation matrix\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n\n    # Select the features with correlations above the threshold\n    # Need to use the absolute value\n    to_drop = [column for column in upper.columns if any(upper[column].abs() > correlation_threshold)]\n\n    n_collinear = len(to_drop)\n    \n    feature_matrix = feature_matrix[[x for x in feature_matrix if x not in to_drop]]\n    print('{} collinear columns removed with correlation above {}.'.format(n_collinear,  correlation_threshold))\n    \n    total_removed = n_missing_cols + n_zero_variance_cols + n_collinear\n    \n    print('Total columns removed: ', total_removed)\n    print('Shape after feature selection: {}.'.format(feature_matrix.shape))\n\n    feature_matrix['idhogar'] = ids\n    feature_matrix = feature_matrix.merge(train_valid_labels, on = 'idhogar', how = 'left')\n\n    \n    # Remove columns derived from the Target\n    drop_cols = []\n    for col in feature_matrix:\n        if col == 'Target':\n            pass\n        else:\n            if 'Target' in col:\n                drop_cols.append(col)\n\n    feature_matrix = feature_matrix[[x for x in feature_matrix if x not in drop_cols]]    \n    \n    # Extract out training and testing data\n    train = feature_matrix[feature_matrix['Target'].notnull()]\n    test = feature_matrix[feature_matrix['Target'].isnull()]\n    \n    # Training labels and testing household ids\n    train_labels = np.array(train.pop('Target')).reshape((-1,))\n    test = test[test['PERCENT_TRUE(ind.parentesco1)'] != 0]\n    test_ids = list(test['idhogar'])\n    \n    test.drop(columns = ['Target', 'idhogar'], inplace = True)\n    train_ids = list(train['idhogar'])\n    \n    # Align the dataframes to ensure they have the same columns\n    train, test = train.align(test, join = 'inner', axis = 1)\n    \n    return train, train_labels, test, test_ids, train_ids",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd9bb3e7007fd0fd89e9ba3d6aaa697f24c2bb5f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train, train_labels, test, test_ids, train_ids = post_process(feature_matrix)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a2959894bbfb468b186dd15d37e0e0ebd117ef17",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "submission, feature_importances, valid_scores = model_gbm(train, train_labels, test, test_ids, 5)\nresults = results.append(pd.DataFrame({'version': ['additional_5fold'], 'F1-mean': [valid_scores.mean()], 'F1-std': [valid_scores.std()]}))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a37531ee288181b9f985450aa97c06cc44d98821",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plot_feature_importances(feature_importances)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "06834ca261ab2b75e4417f3f2d3041bf48a58382"
      },
      "cell_type": "code",
      "source": "submission.to_csv('more_featuretools.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8e70435cbfda1e151c087b4318d1db222c5125d3"
      },
      "cell_type": "markdown",
      "source": "# Add in Divide Primitive\n\nNext we'll add a `divide` transform primitive into the deep feature synthesis call. At first we'll limit the features to 1000. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "166b6194cc9a6ea2d4b190954d7e1ebc3a6a89b7",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "feature_matrix_add, feature_names_add = ft.dfs(entityset=es, target_entity = 'household', \n                                       agg_primitives = ['min', 'max', 'mean', 'percent_true', 'all', 'any',\n                                                         'sum', 'skew', 'std', range_],\n                                       trans_primitives = ['divide'], drop_exact = list(train.columns),\n                                       max_depth = 2, max_features = 1000,\n                                       verbose = 1, n_jobs = -1, \n                                       chunk_size = 100)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8b174453e74e78e80cda0927f55f03861bafa0fd",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "feature_matrix = pd.concat([feature_matrix, feature_matrix_add], axis = 1)\nfeature_matrix.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "55547ea50c03239b0515506aa49d47402c727a33",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train, train_labels, test, test_ids, train_ids = post_process(feature_matrix)\nsubmission, feature_importances, valid_scores = model_gbm(train, train_labels, test, test_ids, 5)\nresults = results.append(pd.DataFrame({'version': ['divide1000_5fold'], 'F1-mean': [valid_scores.mean()], 'F1-std': [valid_scores.std()]}))\nsubmission.to_csv('divide1000_featuretools.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "257ca0f2154e1c04b32dc4766bdd0f5724ca7f61",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plot_feature_importances(feature_importances)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "631fa21b19283dcc653bca4b4b95fbbbac78a964"
      },
      "cell_type": "markdown",
      "source": "## Increase to 1500 features\n\n1000 is clearly not enough! Most of these features are highly correlated, but we can still find useful features as evidenced by the feature importances."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b1f4fb02e0908fc930145d6006d07381c483d4a2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "feature_matrix_add, feature_names_add = ft.dfs(entityset=es, target_entity = 'household', \n                                       agg_primitives = ['min', 'max', 'mean', 'percent_true', 'all', 'any',\n                                                         'sum', 'skew', 'std', range_],\n                                       trans_primitives = ['divide'], drop_exact = list(train.columns),\n                                       max_depth = 2, max_features = 1500,\n                                       verbose = 1, n_jobs = -1, \n                                       chunk_size = 100)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "39232a5fe9ad5a50328666795f01cd593ea42c0f"
      },
      "cell_type": "code",
      "source": "feature_matrix = pd.concat([feature_matrix, feature_matrix_add], axis = 1)\nfeature_matrix.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "232c8ae5e9563664f9756a16894a435b38a470ec",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train, train_labels, test, test_ids, train_ids = post_process(feature_matrix)\nsubmission, feature_importances, valid_scores = model_gbm(train, train_labels, test, test_ids, 5)\nresults = results.append(pd.DataFrame({'version': ['divide1500_5fold'], 'F1-mean': [valid_scores.mean()], 'F1-std': [valid_scores.std()]}))\nsubmission.to_csv('divide1500_featuretools.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80f965bbf639c8215435414ccaae0bb8bf27784c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plot_feature_importances(feature_importances)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "eeca2bdcea18001c2c4b5a6e81aea95e52cbf6f2"
      },
      "cell_type": "markdown",
      "source": "## Go to 2000\n\nThis is getting ridiculous.\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f32aaa7bff19ac8500e59bab0ef6d1c6ee0d2b0",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "feature_matrix_add, feature_names_add = ft.dfs(entityset=es, target_entity = 'household', \n                                       agg_primitives = ['min', 'max', 'mean', 'percent_true', 'all', 'any',\n                                                         'sum', 'skew', 'std', range_],\n                                       trans_primitives = ['divide'], drop_exact = list(train.columns),\n                                       max_depth = 2, max_features = 2000,\n                                       verbose = 1, n_jobs = -1, \n                                       chunk_size = 100)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "7031ea23f1f5c6d36ec1eff2a4bff7f8ace97bcd"
      },
      "cell_type": "code",
      "source": "feature_matrix = pd.concat([feature_matrix, feature_matrix_add], axis = 1)\nfeature_matrix.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c18f5a5bb1985f486b3c2397eedf268b94878ef7",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train, train_labels, test, test_ids, train_ids = post_process(feature_matrix, 0.95, 0.99)\nsubmission, feature_importances, valid_scores = model_gbm(train, train_labels, test, test_ids, 5)\nresults = results.append(pd.DataFrame({'version': ['divide2000_5fold'], 'F1-mean': [valid_scores.mean()], 'F1-std': [valid_scores.std()]}))\nsubmission.to_csv('divide2000_featuretools.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cdde797e836f3db34e27cb08d713358b3577c21f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plot_feature_importances(feature_importances)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "689a9b52e5918b4bbc7555d3d31c740544c40d4f"
      },
      "cell_type": "markdown",
      "source": "# Try Modeling with more folds\n\nAs a final model, we'll increase the number of folds to 10 and see if this results in more stable predictions across folds. It's concerning that there is so much variation between folds, but that is going to happen with a small, imbalanced testing set."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f3a4dac815dc59f7e25d942eebbe396df068272f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "submission, feature_importances, valid_scores = model_gbm(train, train_labels, test, test_ids, 10)\nresults = results.append(pd.DataFrame({'version': ['divide2000_10fold'], 'F1-mean': [valid_scores.mean()], 'F1-std': [valid_scores.std()]}))\nsubmission.to_csv('divide2000_10fold_featuretools.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c9e573ad4386c7a3ad53abb280315dd6d157774e"
      },
      "cell_type": "markdown",
      "source": "# Comparison of Models\n\nAt this point we might honestly ask if there is any benefit to increasing the number of features. Only one way to find out: through data! Let's look at the performance of models so far."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "66ce0f0d8bc5f09f9ae750eaad85587f166d2462",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "results.set_index('version', inplace = True)\n\nresults['F1-mean'].plot.bar(color = 'orange', figsize = (8, 6),\n                                  yerr = list(results['F1-std']))\nplt.title('Model F1 Score Results');\nplt.ylabel('Mean F1 Score (with error bar)');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4f33341a079245e380df66c988e5a98061ccb9f0"
      },
      "cell_type": "markdown",
      "source": "The cross validation accuracy continues to increase as we add features. I think we should be able to add more features as long as we continue to impose feature selection. The gradient boosting machine seems very good at cutting through the swath of features. Eventually we're probably going to be overfitting to the training data, but the we can address that through regularization and feature selection."
    },
    {
      "metadata": {
        "_uuid": "93ff96ca2c72d0b2e90b85fd0e586fb42361ef82"
      },
      "cell_type": "markdown",
      "source": "# Save Data\n\nWe can save the final selected featuretools feature matrix (created with a maximum of 2000 features). This will be used for Bayesian optimization of model hyperparameters. There still might be additional gains to increasing the number of features and/or using different custom primitives. My focus is now going to shift to modeling, but I encourage anyone to keep adjusting the featuretools implementation."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "550c72b79ffd77ed70fe82e96a5582816c32e681"
      },
      "cell_type": "code",
      "source": "train['Target'] = train_labels\ntest['Target'] = np.nan\ntrain['idhogar'] = train_ids\ntest['idhogar'] = test_ids\ndata = train.append(test)\n\nresults.to_csv('model_results.csv', index = True)\ndata.to_csv('ft_2000.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ae8c2f7f1b8a00a2a4fa594943e900f1557e90e8"
      },
      "cell_type": "markdown",
      "source": "# Conclusions\n\nFeaturetools certainly can make our job easier for this problem! Adding features continues to improve the validation score with mixed effects on the public leaderboard. The next step is to optimize the model for these features. __Featuretools should be a default part of your data science workflow.__ The tool is incredibly simple to use and delivers considerable value, creating features that we never would have imagined. I look forward to seeing what the community can come up with for this problem! "
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1cb5b79950978477ae2f932eb824f893256a9a1e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}